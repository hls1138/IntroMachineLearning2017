{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction\n",
    "\n",
    "Dans cet exercice, j’ai utilisé un jeu de donnée issu de Persée. \n",
    "Dans le cadre du cours de méthodologie de projet du master Humanités numériques, j’ai utilisé la nouvelle plateforme de Persée http://data.persee.fr/ pour faire une requête sure le Sparql endpoint de la revue [Communication et Langage](http://www.persee.fr/collection/colan). J’ai pu récupérer un fichier. .csv de tous les titres des articles mis à disposition sur la plateforme (1969 à 2008). J’ai transformé celui-ci en .txt (en appliquant un encodage utf-8) que j’ai ensuite importé dans Jupyter. \n",
    "\n",
    "Le but de cet exercice est de mettre en application les techniques vues en cours de text-mining. Dans un premier temps, nous tenterons d’abord une analyse textuelle (1) afin de savoir quels sont les mots les plus utilisés sur ces titres. Puis nous tenterons de classifier ces derniers (2). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Méthodologie \n",
    "\n",
    "Nous utiliserons numpy/scikit learn et pandas pour la manipulation de nos données. Une des contraintes de ce dataset est l’absence de catégories préexistantes (sujets, thèmes ou catégories des articles). Un lowercasing et la suppression de caractères spéciaux sont appliqués sur le fichier texte (certes au prix d’une réduction de l’information). \n",
    "\n",
    "les caractéristiques des données textuelles sont : \n",
    "* Un fichier de 2470 lignes séparées par un retour chariot\n",
    "* 140 703 caractères de longueur \n",
    "* les titres sont en français \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Analyse de données textuelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "### %matplotlib inline\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "with open(os.path.join(\"C://Users//henry//Desktop//TousLesTitresCL.txt\")) as titres:\n",
    "    titres = [line.strip() for line in titres.readlines()]\n",
    "#Pour vérificication (structure, longueur et type)\n",
    "#print(titres)\n",
    "#len(titres)\n",
    "#type(titres)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je n’ai pas réussi à utiliser les stopwords français inclus dans nltk :\n",
    "from nltk.corpus import stopwords\n",
    "J’ai contourné cette difficulté en téléchargeant une liste [ici](https://github.com/stopwords-iso) que j’ai importée dans mon notebook sous forme de liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pour l'étape suivante nous allons utiliser une liste de stopwords pour enlever de notre tfidfvectorizer les mots les plus courents                 \n",
    "with open('C://Users//henry//Desktop//StopWordsFr.txt', 'r', encoding=\"utf-8\") as StopWords:\n",
    "   StopWords = [line.strip() for line in StopWords.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation de countvectorizer afin de construire un vocabulaire du corpus et de prétraiter le texte (lowercasing, retrait des accents et suppression des stop words en français)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer( encoding='utf-8', max_df=1, strip_accents='unicode',stop_words=StopWords)\n",
    "vectorizer.fit(titres)\n",
    "#vectorizer.vocabulary_ mis en commentaire pour plus de lisibilité\n",
    "#nous avons maintenant un dictionnaire de features\n",
    "vv= vectorizer.vocabulary_\n",
    "type(vv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une tentative de visualisation avec matplotlib (peu lisible et gourmande en RAM à cause de la quantité de mots) les temps de chargements m’ont dissuadé de recourir à d’autres visualisations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAD8CAYAAACyyUlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVJthIkmqzTCRJNX2/yWK6QiOytokAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1db353f1550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Un tel type de visualisation est peu utile compte tenu du nombre de mots dans le dictionnaire. \n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(range(len(vv)), list(vv.values()),)\n",
    "plt.xticks(range(len(vv)), list(vv.keys()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En complément de Count vectorizer, utilisation de TfidfVectorizer.\n",
    "TFxIDF (term frequency-inverse document frequency) permet d’évaluer l’importance des mots dans ce corpus de titres. (plus le mot sera fréquent, plus son poids sera élevé). Les tableaux ci-dessous résument les occurrences de mots les plus présents dans les titres. Le champ lexical des sciences de l’information/communication (et quelques prénoms courants) est sans surprise très présent dans nos résultats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(lowercase=False, stop_words=StopWords)\n",
    "tfidf_vectorizer.fit(titres)\n",
    "#nous traitons le vocabulaire des titres\n",
    "#tfidf_vectorizer.vocabulary_ \n",
    "#mis en commentaire pour plus de lisibilité\n",
    "type(tfidf_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>communication</td>\n",
       "      <td>0.018563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>télévision</td>\n",
       "      <td>0.013515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>livre</td>\n",
       "      <td>0.012311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lecture</td>\n",
       "      <td>0.011555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image</td>\n",
       "      <td>0.011225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>presse</td>\n",
       "      <td>0.010560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>information</td>\n",
       "      <td>0.008909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>publicité</td>\n",
       "      <td>0.008902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jean</td>\n",
       "      <td>0.008033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>médias</td>\n",
       "      <td>0.007421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>typographie</td>\n",
       "      <td>0.006470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>langage</td>\n",
       "      <td>0.006276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>histoire</td>\n",
       "      <td>0.006083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>écriture</td>\n",
       "      <td>0.005990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pierre</td>\n",
       "      <td>0.005882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>art</td>\n",
       "      <td>0.005878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>édition</td>\n",
       "      <td>0.005777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>française</td>\n",
       "      <td>0.005731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>collectif</td>\n",
       "      <td>0.005556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>images</td>\n",
       "      <td>0.005457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ans</td>\n",
       "      <td>0.005375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>france</td>\n",
       "      <td>0.004981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>analyse</td>\n",
       "      <td>0.004918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>temps</td>\n",
       "      <td>0.004861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>direction</td>\n",
       "      <td>0.004848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature     tfidf\n",
       "0   communication  0.018563\n",
       "1      télévision  0.013515\n",
       "2           livre  0.012311\n",
       "3         lecture  0.011555\n",
       "4           image  0.011225\n",
       "5          presse  0.010560\n",
       "6     information  0.008909\n",
       "7       publicité  0.008902\n",
       "8            jean  0.008033\n",
       "9          médias  0.007421\n",
       "10    typographie  0.006470\n",
       "11        langage  0.006276\n",
       "12       histoire  0.006083\n",
       "13       écriture  0.005990\n",
       "14         pierre  0.005882\n",
       "15            art  0.005878\n",
       "16        édition  0.005777\n",
       "17      française  0.005731\n",
       "18      collectif  0.005556\n",
       "19         images  0.005457\n",
       "20            ans  0.005375\n",
       "21         france  0.004981\n",
       "22        analyse  0.004918\n",
       "23          temps  0.004861\n",
       "24      direction  0.004848"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top_mean_feats(Xtr, features, grp_ids=None, min_tfidf=0.1, top_n=25):\n",
    "  # Ici je me suis efforcé de reprendre le code du TD sans toutefois le comprendre à 100%\n",
    "    if grp_ids:\n",
    "        D = Xtr[grp_ids].toarray()\n",
    "    else:\n",
    "        D = Xtr.toarray()\n",
    "    ''' D[D < min_tfidf] = 0 '''\n",
    "    tfidf_means = np.mean(D, axis=0)\n",
    "    return top_tfidf_feats(tfidf_means, features, top_n)\n",
    "\n",
    "top_mean_feats(X_titres, features_titres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>communication</td>\n",
       "      <td>45.850167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>télévision</td>\n",
       "      <td>33.383065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>livre</td>\n",
       "      <td>30.409383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lecture</td>\n",
       "      <td>28.539759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image</td>\n",
       "      <td>27.726581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>presse</td>\n",
       "      <td>26.082672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>information</td>\n",
       "      <td>22.004753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>publicité</td>\n",
       "      <td>21.989089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jean</td>\n",
       "      <td>19.840355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>médias</td>\n",
       "      <td>18.329474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>typographie</td>\n",
       "      <td>15.979900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>langage</td>\n",
       "      <td>15.501142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>histoire</td>\n",
       "      <td>15.024983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>écriture</td>\n",
       "      <td>14.795482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pierre</td>\n",
       "      <td>14.528416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>art</td>\n",
       "      <td>14.519461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>édition</td>\n",
       "      <td>14.269802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>française</td>\n",
       "      <td>14.155746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>collectif</td>\n",
       "      <td>13.723262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>images</td>\n",
       "      <td>13.478759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ans</td>\n",
       "      <td>13.276217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>france</td>\n",
       "      <td>12.303152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>analyse</td>\n",
       "      <td>12.147725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>temps</td>\n",
       "      <td>12.005853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>direction</td>\n",
       "      <td>11.974864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature      tfidf\n",
       "0   communication  45.850167\n",
       "1      télévision  33.383065\n",
       "2           livre  30.409383\n",
       "3         lecture  28.539759\n",
       "4           image  27.726581\n",
       "5          presse  26.082672\n",
       "6     information  22.004753\n",
       "7       publicité  21.989089\n",
       "8            jean  19.840355\n",
       "9          médias  18.329474\n",
       "10    typographie  15.979900\n",
       "11        langage  15.501142\n",
       "12       histoire  15.024983\n",
       "13       écriture  14.795482\n",
       "14         pierre  14.528416\n",
       "15            art  14.519461\n",
       "16        édition  14.269802\n",
       "17      française  14.155746\n",
       "18      collectif  13.723262\n",
       "19         images  13.478759\n",
       "20            ans  13.276217\n",
       "21         france  12.303152\n",
       "22        analyse  12.147725\n",
       "23          temps  12.005853\n",
       "24      direction  11.974864"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Affichage des mots les plus fréquents (selon TFxIDF) :\n",
    "X_titres = tfidf_vectorizer.transform(titres)\n",
    "features_titres = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "D_tf = X_titres.toarray()\n",
    "tf_sum = np.sum(D_tf, axis=0)\n",
    "top_tfidf_feats(tf_sum, features_titres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Classification de données textuelles\n",
    "Utilisation du formalisme sac de mots pour déterminer la forme du corpus. \n",
    "On peut maintenant construire la matrice documents * termes : à l’aide de ce sac. Les titres des articles ne sont pas organisés en catégories nous ne pouvons pas appliquer d’apprentissage tel que la régression logistique utilisée dans le TD5. Pour déterminer quel algorithme appliquer, j’ai fait appel à [cette carte](http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html). Pour ce type de données, le clustering semble plus indiqué : cela va permettre d’utiliser la distance euclidienne pour grouper les mots les plus proches les uns des autres dans notre corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2470, 3339)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classification de données textuelles\n",
    "lines_bag_of_words = vectorizer.transform(titres).toarray()\n",
    "lines_bag_of_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Termes les plus fréquents par clusters\n",
      "Cluster 0:\n",
      " livre\n",
      " presse\n",
      " image\n",
      " publicité\n",
      " information\n",
      " médias\n",
      " jean\n",
      " langage\n",
      " écriture\n",
      " art\n",
      "Cluster 1:\n",
      " typographie\n",
      " nouvelle\n",
      " blanchard\n",
      " typographique\n",
      " foisonnante\n",
      " calligraphie\n",
      " sémiologie\n",
      " classification\n",
      " vers\n",
      " lisibilité\n",
      "Cluster 2:\n",
      " communication\n",
      " entreprise\n",
      " sociologie\n",
      " langages\n",
      " scientifique\n",
      " information\n",
      " temps\n",
      " ans\n",
      " interne\n",
      " publicitaire\n",
      "Cluster 3:\n",
      " édition\n",
      " monde\n",
      " schuwer\n",
      " philippe\n",
      " française\n",
      " livre\n",
      " dictionnaire\n",
      " pascal\n",
      " fouché\n",
      " balle\n",
      "Cluster 4:\n",
      " lecture\n",
      " apprentissage\n",
      " rapide\n",
      " lire\n",
      " école\n",
      " expérience\n",
      " primaire\n",
      " précoce\n",
      " pédagogie\n",
      " chez\n",
      "Cluster 5:\n",
      " journalisme\n",
      " emprise\n",
      " histoire\n",
      " pouvoir\n",
      " historien\n",
      " respect\n",
      " modernité\n",
      " profession\n",
      " investigation\n",
      " mutation\n",
      "Cluster 6:\n",
      " images\n",
      " analyse\n",
      " œuvre\n",
      " contenu\n",
      " image\n",
      " travers\n",
      " art\n",
      " cinéma\n",
      " textes\n",
      " introduction\n",
      "Cluster 7:\n",
      " télévision\n",
      " public\n",
      " jean\n",
      " histoire\n",
      " avenir\n",
      " enfants\n",
      " programmes\n",
      " publique\n",
      " française\n",
      " canadienne\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2646, 3582, 2216, ..., 4542,  902, 1701],\n",
       "       [4558, 3151,  569, ..., 3273, 3274,    0],\n",
       "       [ 977, 1581, 4223, ..., 3206, 3207,    0],\n",
       "       ..., \n",
       "       [2453, 1550, 2124, ..., 3297, 3298,    0],\n",
       "       [2218,  265, 4953, ..., 3251, 3252,    0],\n",
       "       [4588, 3698, 2417, ..., 3236, 3237,    0]], dtype=int64)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "clustering = KMeans(n_clusters=8, init='k-means++', max_iter=1000, n_init=1)\n",
    "clustering.fit(X_titres)\n",
    "#nous souhaitons affichcher les clusters avec les termes les plus proches les uns des autres dans les titres\n",
    "print(\"Termes les plus fréquents par clusters\")\n",
    "centroides = clustering.cluster_centers_.argsort()[:, ::-1]\n",
    "termes = features_titres\n",
    "for i in range(8):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in centroides[i, :10]:\n",
    "        print(' %s' % termes[ind]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J’ai également tenté d’appliquer une autre méthode avec un classifieur naïf de Bayes, ce qui n’a pas bien marché ce qui confirme que les techniques d’apprentissage supervisé sont peu adaptées à ce type de dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=['itc mendoza romane' 'la typographie  entre guillemets'\n 'mademoiselle age tendre\"\"' '...du coup de dés télématique'\n \"4 calligraphes au service de la déclaration universelle des droits de l'homme calendrier édité par la revue non-violence actualité\"\n '4 milliards de journaux, de f. archambault et j.-f. lemoine'\n '6 phrases, 200 sujets, 42 lapsus, 1 rêve'\n '20 ans de la revue en langage, linguistique et lisibilité'\n '20 ans de la revue en publicité et image' '20 ans de revue en mass média'\n '20 ans de revue en édition, communication...' '30/11/92'\n '200 mots à la minute : le débit oral des médias' '248 phrases de proust'\n \"500 éditeurs, à l'heure de l'information\"\n \"1970-1995 : 25 ans de presse d'entreprise en france\"\n '1972 : le symbole du livre'\n \"a l'heure de l'inflation verbale : françois-bernard huygue la langue de coton\"\n \"a l'écoute des téléspectateurs : la permanence téléphonique de tf1\"\n \"a la recherche de l'impact d'une marque\" 'a mi-chemin'\n 'a mi-vie, de j.-l servan-schreiber'\n \"a propos d'abraham moles. la communication : science ou idéologie ?\"\n \"a propos d'un concours pour photographes amateurs\"\n \"a propos d'un dictionnaire typographique\"\n 'a propos de la bourse hachette des chercheurs en communication'\n 'a propos de la bourse hachette des chercheurs en communication (suite)'\n 'a propos de la lecture' 'a propos de la signalisation dans le métro'\n \"a propos de lecture. mais qu'est-ce que lire ?\"\n 'a propos des enfants sourds : la pensée sans langage'\n \"a. m. cassandre ou l'autobiotypographe\"\n 'abraham moles théorie structurale de la communication et société'\n 'académie prisma presse pour la presse magazine'\n 'actes du colloque de cerisy (2004), la nuit en question(s)'\n 'actes i et actes ii, de pierre bourdieu' 'actuel, journal'\n 'adieu, les buttes-chaumont' 'adrian frutiger'\n 'agnès felly vivre à paris, dictionnaire de la signalisation.'\n 'aimer la vie, de j. cazeneuve'\n 'alain berthelot et victor bouadjio écrire et être édité : guide pratique'\n 'alain busson et yves evrard portraits économiques de la culture'\n \"alain le diberder et nathalie coste-cerdan briser les chaînes, introduction a l'après télévision\"\n \"alain sayag et jean-claude lemagny l'invention d'un art. cent-cinquantième anniversaire de la photographie\"\n 'albert hollenstein, typographe visualiste'\n 'albrecht dürer i proportions des lettres traduction de suzanne estève'\n 'alessandrini : jeux typographiques'\n 'alex : un code signalétique canadien' 'alice au pays des dollars'\n 'allemagne-objet... objet de désir' \"alphabets de l'impossible\"\n 'alphabétisation et rééducation de la lecture'\n \"analyse d'une campagne danone\"\n \"analyse d'une œuvre par son auteur : ingmar bergman images\"\n 'analyse de contenu et rewriting journalistique'\n \"analyse de contenu, de marie-christine d'unrug\"\n \"analyse de l'image fixe.\"\n \"analyse de la crise : fabrice piault le livre, la fin d'un règne\"\n \"analyser l'activité du récepteur : le cas des previews\"\n 'andré de peretti organiser des formations'\n 'andré rollin ils écrivent : où ? quand ? comment ?'\n 'anges, mystère et confiture : michel serres la légende des anges'\n \"anne machet si la mémoire m'était comptée, symbolique des nombres et mémoires artificielles de l'antiquité à nos jours\"\n 'anne sauvageot figures de la publicité, figures du monde'\n 'anthropologie de la mort, de l.-v. thomas'\n \"anthropologie et communication : théorie du lien rituel pascal lardellier, postface d'alain caillé\"\n 'anthropologie et glyphes'\n \"apologie d'un zappeur compétent ou la télévision laisse tomber le masque !\"\n \"apport des sciences du langage en communication : le cas de la réunion d'informations en entreprise\"\n \"apprendre l'orthographe\"\n \"apprendre la lecture silencieuse à l'école primaire\"\n 'apprendre la parole. lecture communicationnelle de jacques rancière'\n 'apprendre les langues étrangères à beaubourg'\n 'apprendre à communiquer : j.a. malarewicz guide du voyageur perdu dans les dédales des relations humaines  ; b. sananès acquérir maîtrise, aisance et efficacité dans ses rapports avec les autres : la méthode  clere'\n 'apprendre à lire aux adultes' 'apprendre à lire avant de savoir parler'\n \"apprendre à lire avant l'école\"\n 'apprendre à lire avant six ans, de roger delogne'\n 'apprendre à lire avec la sorcière du star princess'\n 'apprenez les mathématiques à votre bébé, par g. doman'\n 'apprentissage dans le cybermonde. jeux de miroirs et fantasmes de communication'\n 'apprentissage et enseignement'\n 'apprentissage et enseignement de la lecture'\n 'après les autoroutes, le stationnement, etc., la \"\"communication\"\" payante ?'\n 'arabisation et symbole collectif en algérie'\n \"archéologie d'un escamotage : christian licoppe la formation de la pratique scientifique le discours d'expérience en france et en angleterre (1 630-1 820)\"\n \"archéologie de la fiction : isabelle rieusset-lemarié la société des clones à l'ère de la reproduction multimédia\"\n 'arguments linguistiques, de j.c. milner'\n \"ariane levy-schoen et j.k. o' reagan le regard et la lecture\"\n \"ariette farge le goût de l'archive\" 'armand mattelart la publicité'\n 'art et communication marginale, de h. fischer' 'art et ordinateur'\n \"aspects de mise en page des manuscrits de l'egypte pharaonique\"\n 'aspects of french eighteenth century typography, par john dreyfus'\n 'aspects économiques du modèle editorial sur internet'\n 'associations et communication persuasive : il faut se passer des agences-conseils !'\n 'atlas poétique illustré : le livre de tous les pays, par g. jean et m.r. farré'\n 'au cœur de la tribu : henri de camaret les gens de la télévision'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-176-c91483266fe7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines_bag_of_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \"\"\"\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mjll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    722\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"classes_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 724\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    725\u001b[0m         return (safe_sparse_dot(X, self.feature_log_prob_.T) +\n\u001b[0;32m    726\u001b[0m                 self.class_log_prior_)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    408\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    411\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m             \u001b[1;31m# To ensure that array flags are maintained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=['itc mendoza romane' 'la typographie  entre guillemets'\n 'mademoiselle age tendre\"\"' '...du coup de dés télématique'\n \"4 calligraphes au service de la déclaration universelle des droits de l'homme calendrier édité par la revue non-violence actualité\"\n '4 milliards de journaux, de f. archambault et j.-f. lemoine'\n '6 phrases, 200 sujets, 42 lapsus, 1 rêve'\n '20 ans de la revue en langage, linguistique et lisibilité'\n '20 ans de la revue en publicité et image' '20 ans de revue en mass média'\n '20 ans de revue en édition, communication...' '30/11/92'\n '200 mots à la minute : le débit oral des médias' '248 phrases de proust'\n \"500 éditeurs, à l'heure de l'information\"\n \"1970-1995 : 25 ans de presse d'entreprise en france\"\n '1972 : le symbole du livre'\n \"a l'heure de l'inflation verbale : françois-bernard huygue la langue de coton\"\n \"a l'écoute des téléspectateurs : la permanence téléphonique de tf1\"\n \"a la recherche de l'impact d'une marque\" 'a mi-chemin'\n 'a mi-vie, de j.-l servan-schreiber'\n \"a propos d'abraham moles. la communication : science ou idéologie ?\"\n \"a propos d'un concours pour photographes amateurs\"\n \"a propos d'un dictionnaire typographique\"\n 'a propos de la bourse hachette des chercheurs en communication'\n 'a propos de la bourse hachette des chercheurs en communication (suite)'\n 'a propos de la lecture' 'a propos de la signalisation dans le métro'\n \"a propos de lecture. mais qu'est-ce que lire ?\"\n 'a propos des enfants sourds : la pensée sans langage'\n \"a. m. cassandre ou l'autobiotypographe\"\n 'abraham moles théorie structurale de la communication et société'\n 'académie prisma presse pour la presse magazine'\n 'actes du colloque de cerisy (2004), la nuit en question(s)'\n 'actes i et actes ii, de pierre bourdieu' 'actuel, journal'\n 'adieu, les buttes-chaumont' 'adrian frutiger'\n 'agnès felly vivre à paris, dictionnaire de la signalisation.'\n 'aimer la vie, de j. cazeneuve'\n 'alain berthelot et victor bouadjio écrire et être édité : guide pratique'\n 'alain busson et yves evrard portraits économiques de la culture'\n \"alain le diberder et nathalie coste-cerdan briser les chaînes, introduction a l'après télévision\"\n \"alain sayag et jean-claude lemagny l'invention d'un art. cent-cinquantième anniversaire de la photographie\"\n 'albert hollenstein, typographe visualiste'\n 'albrecht dürer i proportions des lettres traduction de suzanne estève'\n 'alessandrini : jeux typographiques'\n 'alex : un code signalétique canadien' 'alice au pays des dollars'\n 'allemagne-objet... objet de désir' \"alphabets de l'impossible\"\n 'alphabétisation et rééducation de la lecture'\n \"analyse d'une campagne danone\"\n \"analyse d'une œuvre par son auteur : ingmar bergman images\"\n 'analyse de contenu et rewriting journalistique'\n \"analyse de contenu, de marie-christine d'unrug\"\n \"analyse de l'image fixe.\"\n \"analyse de la crise : fabrice piault le livre, la fin d'un règne\"\n \"analyser l'activité du récepteur : le cas des previews\"\n 'andré de peretti organiser des formations'\n 'andré rollin ils écrivent : où ? quand ? comment ?'\n 'anges, mystère et confiture : michel serres la légende des anges'\n \"anne machet si la mémoire m'était comptée, symbolique des nombres et mémoires artificielles de l'antiquité à nos jours\"\n 'anne sauvageot figures de la publicité, figures du monde'\n 'anthropologie de la mort, de l.-v. thomas'\n \"anthropologie et communication : théorie du lien rituel pascal lardellier, postface d'alain caillé\"\n 'anthropologie et glyphes'\n \"apologie d'un zappeur compétent ou la télévision laisse tomber le masque !\"\n \"apport des sciences du langage en communication : le cas de la réunion d'informations en entreprise\"\n \"apprendre l'orthographe\"\n \"apprendre la lecture silencieuse à l'école primaire\"\n 'apprendre la parole. lecture communicationnelle de jacques rancière'\n 'apprendre les langues étrangères à beaubourg'\n 'apprendre à communiquer : j.a. malarewicz guide du voyageur perdu dans les dédales des relations humaines  ; b. sananès acquérir maîtrise, aisance et efficacité dans ses rapports avec les autres : la méthode  clere'\n 'apprendre à lire aux adultes' 'apprendre à lire avant de savoir parler'\n \"apprendre à lire avant l'école\"\n 'apprendre à lire avant six ans, de roger delogne'\n 'apprendre à lire avec la sorcière du star princess'\n 'apprenez les mathématiques à votre bébé, par g. doman'\n 'apprentissage dans le cybermonde. jeux de miroirs et fantasmes de communication'\n 'apprentissage et enseignement'\n 'apprentissage et enseignement de la lecture'\n 'après les autoroutes, le stationnement, etc., la \"\"communication\"\" payante ?'\n 'arabisation et symbole collectif en algérie'\n \"archéologie d'un escamotage : christian licoppe la formation de la pratique scientifique le discours d'expérience en france et en angleterre (1 630-1 820)\"\n \"archéologie de la fiction : isabelle rieusset-lemarié la société des clones à l'ère de la reproduction multimédia\"\n 'arguments linguistiques, de j.c. milner'\n \"ariane levy-schoen et j.k. o' reagan le regard et la lecture\"\n \"ariette farge le goût de l'archive\" 'armand mattelart la publicité'\n 'art et communication marginale, de h. fischer' 'art et ordinateur'\n \"aspects de mise en page des manuscrits de l'egypte pharaonique\"\n 'aspects of french eighteenth century typography, par john dreyfus'\n 'aspects économiques du modèle editorial sur internet'\n 'associations et communication persuasive : il faut se passer des agences-conseils !'\n 'atlas poétique illustré : le livre de tous les pays, par g. jean et m.r. farré'\n 'au cœur de la tribu : henri de camaret les gens de la télévision'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB().fit(lines_bag_of_words, titres)\n",
    "classifier.predict(titres[:100])\n",
    "#classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "En conclusion, l’analyse par vectorisation et le clustering par Kmeans ont permis de bien identifier les thématiques de cette revue en mettant en avant des faits intéressants : plus de titres parlent de la télévision que de livres et de la presse par exemple. \n",
    "Le clustering permet d’identifier des termes proches les uns des autres ainsi que donner des pistes d’utilisation : le cluster 4 associant « lecture, apprentissage, rapide, lire, école, expérience, primaire, précoce, pédagogie, chez » montre bien la préoccupation et les centres d’intérêt des auteurs de cette revue.\n",
    "\n",
    "Le cluster 5 souligne les enjeux et le champ lexical liés au thème du journalisme. \n",
    "J’ai beaucoup apprécié cette application pratique du cours, je regrette cependant la difficulté pour visualiser ce type de corpus, et le fait de ne pas avoir eu le temps de tester plus de méthodes issues du formidable outil qu’est sklearn. J’aurai également souhaité voir en quoi la bibliothèque nltk aurait pu proposer une approche différente. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
